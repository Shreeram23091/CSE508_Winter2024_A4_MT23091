{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8174273,"sourceType":"datasetVersion","datasetId":4838346},{"sourceId":8200891,"sourceType":"datasetVersion","datasetId":4858240}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the Transformers library using pip\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:59:26.572687Z","iopub.execute_input":"2024-04-23T03:59:26.572992Z","iopub.status.idle":"2024-04-23T03:59:40.748434Z","shell.execute_reply.started":"2024-04-23T03:59:26.572964Z","shell.execute_reply":"2024-04-23T03:59:40.746792Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing required libraries\nimport re  # Regular expression library for text processing\nimport random  # Random number generation for shuffling data\nimport pandas as pd  # Pandas library for handling data frames\nimport numpy as np  # NumPy library for numerical computations\nimport torch  # PyTorch library for deep learning\nfrom torch.utils.data import Dataset, DataLoader  # Data loading utilities from PyTorch\nfrom transformers import AutoTokenizer, AutoModelWithLMHead  # Hugging Face Transformers library for pretrained models\nimport torch.optim as optim  # PyTorch library for optimization algorithms\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:59:40.750975Z","iopub.execute_input":"2024-04-23T03:59:40.751418Z","iopub.status.idle":"2024-04-23T03:59:46.794071Z","shell.execute_reply.started":"2024-04-23T03:59:40.751371Z","shell.execute_reply":"2024-04-23T03:59:46.793248Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Check if CUDA GPU is available, otherwise use CPU\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# Print the device being used (CUDA GPU or CPU)\ndevice\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:59:56.481966Z","iopub.execute_input":"2024-04-23T03:59:56.482801Z","iopub.status.idle":"2024-04-23T03:59:56.519476Z","shell.execute_reply.started":"2024-04-23T03:59:56.482766Z","shell.execute_reply":"2024-04-23T03:59:56.518584Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"import csv\n\n# Path to the CSV file containing reviews\nreviews_path = \"/kaggle/input/ir-a4-dataset/Reviews.csv\"\n\n# List to store reviews as strings\nreviews = []\n\n# Open the CSV file\nwith open(reviews_path, \"r\", encoding=\"utf-8\") as reviews_raw:\n    # Create a CSV reader object\n    csv_reader = csv.DictReader(reviews_raw)\n    # Iterate over each row in the CSV file\n    for row in csv_reader:\n        # Extract summary and text from the current row\n        summary = row[\"Summary\"]\n        text = row[\"Text\"]\n        # Replace \" = \" with \" TL;DR \" in summary and text\n        summary = summary.replace(\" = \", \" TL;DR \")\n        text = text.replace(\" = \", \" TL;DR \")\n        # Combine summary and text into one string, separated by \" = \"\n        review = f\"{text.strip()} = {summary.strip()}\\n\"\n        # Append the combined review to the list of reviews\n        reviews.append(review)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:59:59.419028Z","iopub.execute_input":"2024-04-23T03:59:59.419737Z","iopub.status.idle":"2024-04-23T04:00:06.598782Z","shell.execute_reply.started":"2024-04-23T03:59:59.419701Z","shell.execute_reply":"2024-04-23T04:00:06.597969Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Display the first 5 reviews in the list\nreviews[:5]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:39:17.285757Z","iopub.execute_input":"2024-04-23T03:39:17.286154Z","iopub.status.idle":"2024-04-23T03:39:17.292472Z","shell.execute_reply.started":"2024-04-23T03:39:17.286121Z","shell.execute_reply":"2024-04-23T03:39:17.291588Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. = Good Quality Dog Food\\n',\n 'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". = Not as Advertised\\n',\n 'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch. = \"Delight\" says it all\\n',\n 'If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal. = Cough Medicine\\n',\n 'Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal. = Great taffy\\n']"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate the number of reviews in the dataset\nlen(reviews)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:39:36.971969Z","iopub.execute_input":"2024-04-23T03:39:36.972895Z","iopub.status.idle":"2024-04-23T03:39:36.978691Z","shell.execute_reply.started":"2024-04-23T03:39:36.972851Z","shell.execute_reply":"2024-04-23T03:39:36.977638Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"568454"},"metadata":{}}]},{"cell_type":"code","source":"# Display the 11th review in the dataset\nreviews[10]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:40:06.346025Z","iopub.execute_input":"2024-04-23T03:40:06.346888Z","iopub.status.idle":"2024-04-23T03:40:06.353270Z","shell.execute_reply.started":"2024-04-23T03:40:06.346836Z","shell.execute_reply":"2024-04-23T03:40:06.352213Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service! = The Best Hot Sauce in the World\\n\""},"metadata":{}}]},{"cell_type":"code","source":"# Calculate the average length of reviews in terms of number of words\navg_length = sum([len(review.split()) for review in reviews]) / len(reviews)\navg_length\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T03:40:28.742630Z","iopub.execute_input":"2024-04-23T03:40:28.743123Z","iopub.status.idle":"2024-04-23T03:40:31.822117Z","shell.execute_reply.started":"2024-04-23T03:40:28.743091Z","shell.execute_reply":"2024-04-23T03:40:31.821144Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"85.37717211946789"},"metadata":{}}]},{"cell_type":"code","source":"# Define the maximum length of the reviews\nmax_length = 100\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:01:53.425910Z","iopub.execute_input":"2024-04-23T04:01:53.426615Z","iopub.status.idle":"2024-04-23T04:01:53.430941Z","shell.execute_reply.started":"2024-04-23T04:01:53.426577Z","shell.execute_reply":"2024-04-23T04:01:53.429962Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Initialize the GPT-2 tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\n# Initialize the GPT-2 model\nmodel = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:01:56.355999Z","iopub.execute_input":"2024-04-23T04:01:56.356459Z","iopub.status.idle":"2024-04-23T04:01:56.964599Z","shell.execute_reply.started":"2024-04-23T04:01:56.356424Z","shell.execute_reply":"2024-04-23T04:01:56.963347Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1682: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Move the model to the appropriate device (GPU or CPU)\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:00:37.357337Z","iopub.execute_input":"2024-04-23T04:00:37.357735Z","iopub.status.idle":"2024-04-23T04:00:37.365036Z","shell.execute_reply.started":"2024-04-23T04:00:37.357705Z","shell.execute_reply":"2024-04-23T04:00:37.364113Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the optimizer\noptimizer = optim.AdamW(model.parameters(), lr=3e-4)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:00:40.467489Z","iopub.execute_input":"2024-04-23T04:00:40.467871Z","iopub.status.idle":"2024-04-23T04:00:40.474276Z","shell.execute_reply.started":"2024-04-23T04:00:40.467842Z","shell.execute_reply":"2024-04-23T04:00:40.472972Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Encode the special token \"TL;DR\" using the tokenizer\nencoded_token = tokenizer.encode(\" TL;DR \")\nencoded_token\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:00:43.012292Z","iopub.execute_input":"2024-04-23T04:00:43.013234Z","iopub.status.idle":"2024-04-23T04:00:43.022220Z","shell.execute_reply.started":"2024-04-23T04:00:43.013197Z","shell.execute_reply":"2024-04-23T04:00:43.021231Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[24811, 26, 7707, 220]"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate the length of the special token \"TL;DR\"\nextra_length = len(tokenizer.encode(\" TL;DR \")) \nextra_length\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:00:45.715133Z","iopub.execute_input":"2024-04-23T04:00:45.716020Z","iopub.status.idle":"2024-04-23T04:00:45.722908Z","shell.execute_reply.started":"2024-04-23T04:00:45.715975Z","shell.execute_reply":"2024-04-23T04:00:45.722031Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"code","source":"class ReviewDataset(Dataset):  \n    def __init__(self, tokenizer, reviews, max_len):\n        \"\"\"\n        Initialize the ReviewDataset class.\n\n        Args:\n            tokenizer (transformers.tokenization_utils_base.PreTrainedTokenizer): Tokenizer object.\n            reviews (list): List of reviews as strings.\n            max_len (int): Maximum length of the input sequence.\n        \"\"\"\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.eos = self.tokenizer.eos_token\n        self.eos_id = self.tokenizer.eos_token_id\n        self.reviews = reviews\n        self.result = []\n\n        # Process each review in the dataset\n        for review in self.reviews:\n            # Encode the text using tokenizer.encode(). We add EOS at the end\n            tokenized = self.tokenizer.encode(review + self.eos)\n            \n            # Padding/truncating the encoded sequence to max_len \n            padded = self.pad_truncate(tokenized)            \n\n            # Creating a tensor and adding to the result\n            self.result.append(torch.tensor(padded))\n\n    def __len__(self):\n        \"\"\"\n        Get the total number of reviews in the dataset.\n\n        Returns:\n            int: Total number of reviews.\n        \"\"\"\n        return len(self.result)\n\n    def __getitem__(self, item):\n        \"\"\"\n        Get a specific review item from the dataset.\n\n        Args:\n            item (int): Index of the review item.\n\n        Returns:\n            torch.Tensor: Encoded review tensor.\n        \"\"\"\n        return self.result[item]\n\n    def pad_truncate(self, name):\n        \"\"\"\n        Pad or truncate the encoded review sequence to match the max_len.\n\n        Args:\n            name (list): Encoded review sequence.\n\n        Returns:\n            list: Padded or truncated review sequence.\n        \"\"\"\n        name_length = len(name) - extra_length\n        if name_length < self.max_len:\n            difference = self.max_len - name_length\n            result = name + [self.eos_id] * difference\n        elif name_length > self.max_len:\n            result = name[:self.max_len + 3] + [self.eos_id] \n        else:\n            result = name\n        return result\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:00:52.039156Z","iopub.execute_input":"2024-04-23T04:00:52.039922Z","iopub.status.idle":"2024-04-23T04:00:52.051108Z","shell.execute_reply.started":"2024-04-23T04:00:52.039887Z","shell.execute_reply":"2024-04-23T04:00:52.049909Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Create an instance of the ReviewDataset class\n# Parameters:\n#   tokenizer: The tokenizer object used for tokenization\n#   reviews: List of review strings\n#   max_length: Maximum length of tokenized sequences\ndataset = ReviewDataset(tokenizer, reviews, max_length)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:08:56.758988Z","iopub.execute_input":"2024-04-23T04:08:56.759395Z","iopub.status.idle":"2024-04-23T04:13:43.475342Z","shell.execute_reply.started":"2024-04-23T04:08:56.759365Z","shell.execute_reply":"2024-04-23T04:13:43.474284Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# DATALOADER","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create a DataLoader instance for batching and shuffling the dataset\n# Parameters:\n#   dataset: The dataset object to load batches from\n#   batch_size: The number of samples per batch\n#   shuffle: Whether to shuffle the dataset before each epoch\n#   drop_last: Whether to drop the last incomplete batch if its size is less than the specified batch size\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True, drop_last=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:15:46.580530Z","iopub.execute_input":"2024-04-23T04:15:46.581317Z","iopub.status.idle":"2024-04-23T04:15:47.364661Z","shell.execute_reply.started":"2024-04-23T04:15:46.581273Z","shell.execute_reply":"2024-04-23T04:15:47.363787Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, dl, epochs):    \n    # Iterate over the specified number of epochs\n    for epoch in range(epochs):\n        # Iterate over each batch in the data loader\n        for idx, batch in enumerate(dl):\n            # Enable gradient calculation for the model parameters\n            with torch.set_grad_enabled(True):\n                # Clear the gradients from the previous iteration\n                optimizer.zero_grad()\n                # Move the batch to the appropriate device (GPU or CPU)\n                batch = batch.to(device)\n                # Forward pass: compute the model's predictions and loss\n                output = model(batch, labels=batch)\n                loss = output[0]\n                # Backward pass: compute gradients of the loss with respect to model parameters\n                loss.backward()\n                # Update model parameters using the gradients and optimizer\n                optimizer.step()\n                # Print the loss at specified intervals\n                if idx % 50 == 0:\n                    print(\"loss: %f, %d\"%(loss, idx))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:15:54.109565Z","iopub.execute_input":"2024-04-23T04:15:54.110552Z","iopub.status.idle":"2024-04-23T04:15:54.117511Z","shell.execute_reply.started":"2024-04-23T04:15:54.110514Z","shell.execute_reply":"2024-04-23T04:15:54.116513Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train(model=model, optimizer=optimizer, dl=dataloader, epochs=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T11:15:35.395036Z","iopub.execute_input":"2024-04-22T11:15:35.395333Z","iopub.status.idle":"2024-04-22T13:32:17.596943Z","shell.execute_reply.started":"2024-04-22T11:15:35.395308Z","shell.execute_reply":"2024-04-22T13:32:17.596086Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"loss: 7.179998, 0\nloss: 2.546208, 50\nloss: 2.173442, 100\nloss: 2.687057, 150\nloss: 2.299516, 200\nloss: 2.323481, 250\nloss: 2.308963, 300\nloss: 2.470415, 350\nloss: 2.384151, 400\nloss: 2.411604, 450\nloss: 2.191579, 500\nloss: 2.710379, 550\nloss: 2.356698, 600\nloss: 2.104545, 650\nloss: 2.092360, 700\nloss: 2.215420, 750\nloss: 2.406816, 800\nloss: 2.368682, 850\nloss: 2.637617, 900\nloss: 2.189571, 950\nloss: 2.308575, 1000\nloss: 2.238402, 1050\nloss: 2.063868, 1100\nloss: 2.344211, 1150\nloss: 2.464975, 1200\nloss: 2.153612, 1250\nloss: 2.138024, 1300\nloss: 2.524029, 1350\nloss: 2.249254, 1400\nloss: 2.285464, 1450\nloss: 2.017530, 1500\nloss: 1.820162, 1550\nloss: 2.174565, 1600\nloss: 2.552882, 1650\nloss: 2.148380, 1700\nloss: 2.165045, 1750\nloss: 2.298380, 1800\nloss: 2.125666, 1850\nloss: 2.262254, 1900\nloss: 2.293321, 1950\nloss: 2.087833, 2000\nloss: 2.001413, 2050\nloss: 2.193791, 2100\nloss: 2.232748, 2150\nloss: 2.245459, 2200\nloss: 2.175688, 2250\nloss: 2.203779, 2300\nloss: 2.333107, 2350\nloss: 2.174418, 2400\nloss: 2.005616, 2450\nloss: 2.140307, 2500\nloss: 2.320475, 2550\nloss: 2.034000, 2600\nloss: 1.952949, 2650\nloss: 2.201778, 2700\nloss: 1.886993, 2750\nloss: 2.196239, 2800\nloss: 2.075902, 2850\nloss: 2.085238, 2900\nloss: 2.418180, 2950\nloss: 2.034922, 3000\nloss: 1.908317, 3050\nloss: 2.503305, 3100\nloss: 2.476161, 3150\nloss: 2.130602, 3200\nloss: 2.035571, 3250\nloss: 2.077102, 3300\nloss: 2.369753, 3350\nloss: 2.246732, 3400\nloss: 2.122199, 3450\nloss: 2.375435, 3500\nloss: 2.134913, 3550\nloss: 2.200869, 3600\nloss: 2.202316, 3650\nloss: 2.124436, 3700\nloss: 2.127747, 3750\nloss: 2.236326, 3800\nloss: 2.151803, 3850\nloss: 1.962897, 3900\nloss: 2.054335, 3950\nloss: 1.915839, 4000\nloss: 2.030221, 4050\nloss: 2.170536, 4100\nloss: 1.951652, 4150\nloss: 2.320496, 4200\nloss: 2.102848, 4250\nloss: 2.255838, 4300\nloss: 2.369204, 4350\nloss: 2.084755, 4400\nloss: 2.397063, 4450\nloss: 1.934528, 4500\nloss: 2.214739, 4550\nloss: 2.275740, 4600\nloss: 1.953343, 4650\nloss: 1.905339, 4700\nloss: 2.274620, 4750\nloss: 2.203720, 4800\nloss: 2.447945, 4850\nloss: 2.073444, 4900\nloss: 2.244152, 4950\nloss: 2.092780, 5000\nloss: 2.122076, 5050\nloss: 2.215444, 5100\nloss: 2.002038, 5150\nloss: 2.227186, 5200\nloss: 2.073352, 5250\nloss: 1.994648, 5300\nloss: 2.147708, 5350\nloss: 2.171522, 5400\nloss: 2.021449, 5450\nloss: 2.277795, 5500\nloss: 2.065826, 5550\nloss: 2.006109, 5600\nloss: 2.222303, 5650\nloss: 2.145988, 5700\nloss: 1.988699, 5750\nloss: 2.416167, 5800\nloss: 2.175748, 5850\nloss: 2.003775, 5900\nloss: 2.046824, 5950\nloss: 2.189290, 6000\nloss: 2.265274, 6050\nloss: 1.808317, 6100\nloss: 1.829223, 6150\nloss: 1.955007, 6200\nloss: 2.240872, 6250\nloss: 2.235186, 6300\nloss: 2.041268, 6350\nloss: 2.035798, 6400\nloss: 2.236791, 6450\nloss: 2.020753, 6500\nloss: 2.066976, 6550\nloss: 1.782139, 6600\nloss: 2.219458, 6650\nloss: 2.132128, 6700\nloss: 2.053517, 6750\nloss: 2.033494, 6800\nloss: 2.018213, 6850\nloss: 2.059720, 6900\nloss: 2.386530, 6950\nloss: 2.163881, 7000\nloss: 1.997306, 7050\nloss: 2.115539, 7100\nloss: 2.318241, 7150\nloss: 2.365331, 7200\nloss: 2.207479, 7250\nloss: 2.244404, 7300\nloss: 2.063596, 7350\nloss: 2.148598, 7400\nloss: 2.168213, 7450\nloss: 2.177212, 7500\nloss: 1.904301, 7550\nloss: 2.093769, 7600\nloss: 1.978347, 7650\nloss: 2.098054, 7700\nloss: 2.169493, 7750\nloss: 2.085661, 7800\nloss: 1.886774, 7850\nloss: 2.510666, 7900\nloss: 1.984088, 7950\nloss: 1.963435, 8000\nloss: 2.218378, 8050\nloss: 2.078304, 8100\nloss: 2.104980, 8150\nloss: 2.195798, 8200\nloss: 1.712596, 8250\nloss: 1.887635, 8300\nloss: 2.009505, 8350\nloss: 2.199556, 8400\nloss: 2.034193, 8450\nloss: 2.181220, 8500\nloss: 1.786736, 8550\nloss: 1.870662, 8600\nloss: 1.907265, 8650\nloss: 1.980892, 8700\nloss: 1.855423, 8750\nloss: 2.065232, 8800\nloss: 2.271160, 8850\nloss: 2.212322, 8900\nloss: 2.073380, 8950\nloss: 2.051777, 9000\nloss: 2.061492, 9050\nloss: 2.065233, 9100\nloss: 2.000200, 9150\nloss: 2.214236, 9200\nloss: 1.750447, 9250\nloss: 2.013983, 9300\nloss: 1.929532, 9350\nloss: 1.751237, 9400\nloss: 2.284103, 9450\nloss: 2.029752, 9500\nloss: 2.249203, 9550\nloss: 2.154821, 9600\nloss: 1.940630, 9650\nloss: 1.949405, 9700\nloss: 2.269420, 9750\nloss: 2.016193, 9800\nloss: 1.720772, 9850\nloss: 2.148767, 9900\nloss: 1.938862, 9950\nloss: 1.986837, 10000\nloss: 1.899756, 10050\nloss: 2.005066, 10100\nloss: 2.186970, 10150\nloss: 1.826530, 10200\nloss: 1.976253, 10250\nloss: 1.915622, 10300\nloss: 2.445463, 10350\nloss: 1.949667, 10400\nloss: 2.033354, 10450\nloss: 2.000247, 10500\nloss: 2.143237, 10550\nloss: 1.976022, 10600\nloss: 2.054891, 10650\nloss: 1.927113, 10700\nloss: 1.998320, 10750\nloss: 2.214032, 10800\nloss: 1.865538, 10850\nloss: 2.020538, 10900\nloss: 1.775335, 10950\nloss: 2.042610, 11000\nloss: 2.026172, 11050\nloss: 1.941727, 11100\nloss: 1.800531, 11150\nloss: 2.087330, 11200\nloss: 1.973143, 11250\nloss: 1.870570, 11300\nloss: 2.059785, 11350\nloss: 2.085273, 11400\nloss: 2.109655, 11450\nloss: 1.994739, 11500\nloss: 1.864831, 11550\nloss: 1.718140, 11600\nloss: 1.817069, 11650\nloss: 2.133237, 11700\nloss: 1.800212, 11750\nloss: 2.162971, 11800\nloss: 2.038387, 11850\nloss: 1.986510, 11900\nloss: 2.081030, 11950\nloss: 1.835257, 12000\nloss: 2.328672, 12050\nloss: 1.724025, 12100\nloss: 1.751005, 12150\nloss: 1.877854, 12200\nloss: 1.936718, 12250\nloss: 1.924222, 12300\nloss: 1.992618, 12350\nloss: 1.995885, 12400\nloss: 2.182284, 12450\nloss: 2.126747, 12500\nloss: 1.975394, 12550\nloss: 1.836168, 12600\nloss: 2.267316, 12650\nloss: 1.854945, 12700\nloss: 2.052965, 12750\nloss: 1.885056, 12800\nloss: 2.154880, 12850\nloss: 1.799294, 12900\nloss: 1.945950, 12950\nloss: 2.175445, 13000\nloss: 1.725501, 13050\nloss: 1.912111, 13100\nloss: 1.566902, 13150\nloss: 2.184010, 13200\nloss: 1.778355, 13250\nloss: 1.827977, 13300\nloss: 1.982434, 13350\nloss: 1.919181, 13400\nloss: 1.851663, 13450\nloss: 1.915917, 13500\nloss: 2.049237, 13550\nloss: 1.614667, 13600\nloss: 1.951115, 13650\nloss: 1.971087, 13700\nloss: 2.019321, 13750\nloss: 1.785248, 13800\nloss: 1.938199, 13850\nloss: 1.888795, 13900\nloss: 1.992351, 13950\nloss: 2.044557, 14000\nloss: 2.053672, 14050\nloss: 2.098352, 14100\nloss: 2.236063, 14150\nloss: 1.881279, 14200\nloss: 2.199512, 14250\nloss: 1.765493, 14300\nloss: 2.105541, 14350\nloss: 2.120003, 14400\nloss: 2.153830, 14450\nloss: 1.797022, 14500\nloss: 1.759722, 14550\nloss: 1.919263, 14600\nloss: 1.950946, 14650\nloss: 1.915567, 14700\nloss: 1.879333, 14750\nloss: 1.876890, 14800\nloss: 2.255475, 14850\nloss: 1.770617, 14900\nloss: 1.494443, 14950\nloss: 1.816499, 15000\nloss: 1.873335, 15050\nloss: 2.096269, 15100\nloss: 1.895371, 15150\nloss: 2.235538, 15200\nloss: 1.967900, 15250\nloss: 2.165826, 15300\nloss: 1.865141, 15350\nloss: 1.840579, 15400\nloss: 1.992269, 15450\nloss: 2.109605, 15500\nloss: 1.873654, 15550\nloss: 1.867358, 15600\nloss: 1.997511, 15650\nloss: 1.770107, 15700\nloss: 1.756370, 15750\nloss: 2.224028, 15800\nloss: 1.503791, 15850\nloss: 2.109290, 15900\nloss: 1.984638, 15950\nloss: 1.936308, 16000\nloss: 1.872335, 16050\nloss: 1.899984, 16100\nloss: 1.735803, 16150\nloss: 1.835989, 16200\nloss: 2.043731, 16250\nloss: 1.798785, 16300\nloss: 1.807341, 16350\nloss: 1.965681, 16400\nloss: 1.795312, 16450\nloss: 1.939250, 16500\nloss: 1.690184, 16550\nloss: 1.644580, 16600\nloss: 2.069916, 16650\nloss: 2.255896, 16700\nloss: 1.822145, 16750\nloss: 2.038384, 16800\nloss: 2.153052, 16850\nloss: 2.011309, 16900\nloss: 1.799299, 16950\nloss: 2.077619, 17000\nloss: 2.137277, 17050\nloss: 2.003010, 17100\nloss: 1.854963, 17150\nloss: 1.886199, 17200\nloss: 1.904608, 17250\nloss: 1.798188, 17300\nloss: 1.999772, 17350\nloss: 1.607766, 17400\nloss: 2.025405, 17450\nloss: 2.107935, 17500\nloss: 2.026344, 17550\nloss: 1.773535, 17600\nloss: 2.227053, 17650\nloss: 2.090322, 17700\nloss: 1.871062, 17750\n","output_type":"stream"}]},{"cell_type":"code","source":"def topk(probs, n=9):\n    # Softmax operation to convert scores to probabilities\n    probs = torch.softmax(probs, dim=-1)\n    \n    # Extract top k tokens and their probabilities\n    tokensProb, topIx = torch.topk(probs, k=n)\n    \n    # Normalize the probabilities to ensure they sum up to 1\n    tokensProb = tokensProb / torch.sum(tokensProb)\n    \n    # Convert probabilities to numpy array for random selection\n    tokensProb = tokensProb.cpu().detach().numpy()\n    \n    # Randomly select a token based on the probabilities\n    choice = np.random.choice(n, 1, p=tokensProb)\n    tokenId = topIx[choice][0]\n\n    return int(tokenId)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:16:08.459076Z","iopub.execute_input":"2024-04-23T04:16:08.459504Z","iopub.status.idle":"2024-04-23T04:16:08.465992Z","shell.execute_reply.started":"2024-04-23T04:16:08.459469Z","shell.execute_reply":"2024-04-23T04:16:08.464975Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def model_infer(model, tokenizer, review, max_length=15):\n    # Tokenize the initial review\n    review_encoded = tokenizer.encode(review)\n    result = review_encoded\n    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n\n    with torch.set_grad_enabled(False):\n        # Feed the initial token to the model\n        output = model(initial_input)\n\n        # Get the logits for the next token\n        logits = output.logits[0, -1]\n\n        # Make a top-k choice and append to the result\n        result.append(topk(logits))\n\n        # For max_length times:\n        for _ in range(max_length):\n            # Feed the current sequence to the model and make a choice\n            input = torch.tensor(result).unsqueeze(0).to(device)\n            output = model(input)\n            logits = output.logits[0, -1]\n            res_id = topk(logits)\n\n            # If the chosen token is EOS, return the result\n            if res_id == tokenizer.eos_token_id:\n                return tokenizer.decode(result)\n            else:  # Append to the sequence\n                result.append(res_id)\n    # If no EOS token is generated, return after reaching max_length\n    return tokenizer.decode(result)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:39:41.237349Z","iopub.execute_input":"2024-04-23T04:39:41.238275Z","iopub.status.idle":"2024-04-23T04:39:41.247148Z","shell.execute_reply.started":"2024-04-23T04:39:41.238242Z","shell.execute_reply":"2024-04-23T04:39:41.246105Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"sample_reviews = [review.split(\" TL;DR \")[0] for review in random.sample(reviews, 5)]\nsample_reviews","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:17:59.078424Z","iopub.execute_input":"2024-04-23T04:17:59.078848Z","iopub.status.idle":"2024-04-23T04:17:59.085471Z","shell.execute_reply.started":"2024-04-23T04:17:59.078819Z","shell.execute_reply":"2024-04-23T04:17:59.084557Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['I loved this brand.  It was the best vanilla flavor of others I tried.  I would buy more if it was a better price. = Wolfgang puck coffee vanilla francaise\\n',\n 'Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\\n',\n 'I order this food to try as it was grain free and I liked the ingredients listed on the site with the reviews. I opened the bag and the smell was incredible. It almost made me hungry lol. The dog loves it and is doing well on it.<br />  I start doing more research on the food and was very impressed. The owners of this food make sure ethoxyquin, BHA and BHT (which are knowing to cause cancer) are NOT used at all in the food. They make sure that the slaughter and processing plants do not use them either. That is great and it show that they care as well.<br />  I have communicated with the Petcurean and have been very impressed with them as well. I am really happy with this food. It has very good ingredients. he company is great. I highly recommended this good and I have tired several different grain free dog foods.  Plus my dog loves it.<br />  Thank you amazon. i would have never found it without amazon. = Incrediblely Great food with great results.\\n',\n 'I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor\\'s has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I\\'d say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor\\'s, for making a product that is so worth purchasing and using! Can\\'t live, or at least cook, without my Minor\\'s! = Cookin\\' in Arizona\\n',\n \"I absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\\n\"]"},"metadata":{}}]},{"cell_type":"code","source":"for review in sample_reviews:\n    summaries = set()\n    print(review)\n    while len(summaries) < 3:\n        # Print the result of model_infer before splitting\n        result = model_infer(model, tokenizer, review + \" TL;DR \")\n        print(\"Result:\", result)\n        \n        # Split the result and print the parts\n        parts = result.split(\" TL;DR \")\n        print(\"Parts:\", parts)\n        \n        # Try to access the second part after splitting\n        if len(parts) > 1:\n            summary = parts[1].strip()\n            if summary not in summaries:\n                summaries.add(summary)\n        print(\"Summaries:\", summaries)\n        \n        # Break out of the loop once three summaries are collected\n        if len(summaries) >= 1:\n            break\n    print(\"\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:39:58.921945Z","iopub.execute_input":"2024-04-23T04:39:58.922422Z","iopub.status.idle":"2024-04-23T04:40:01.384659Z","shell.execute_reply.started":"2024-04-23T04:39:58.922380Z","shell.execute_reply":"2024-04-23T04:40:01.383548Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"I loved this brand.  It was the best vanilla flavor of others I tried.  I would buy more if it was a better price. = Wolfgang puck coffee vanilla francaise\n\nResult: I loved this brand.  It was the best vanilla flavor of others I tried.  I would buy more if it was a better price. = Wolfgang puck coffee vanilla francaise\n TL;DR  If you love vanilla, this is the right price for you. = The\nParts: ['I loved this brand.  It was the best vanilla flavor of others I tried.  I would buy more if it was a better price. = Wolfgang puck coffee vanilla francaise\\n', '\\xa0If you love vanilla, this is the right price for you. = The']\nSummaries: {'If you love vanilla, this is the right price for you. = The'}\n\n\nSeriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\n\nResult: Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\n TL;DR!!! If you want to have fun with your gum, go buy this gum now\nParts: ['Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\\n TL;DR!!! If you want to have fun with your gum, go buy this gum now']\nSummaries: set()\nResult: Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\n TL;DR!!!!\n\nI have to say this is my favorite gum. I love it\nParts: ['Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\\n TL;DR!!!!\\n\\nI have to say this is my favorite gum. I love it']\nSummaries: set()\nResult: Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\n TL;DR ______________________________________I bought the first version of this product because it came with two packs\nParts: ['Seriously,<br /><br />this has to be the best tasting Spearmint gum out there. And on top of that it is sugar free and good for your teeth. Without those nasty, artificial sweeteners. That has to be chewing gum heaven. I would definitely recommend this product!!! = the best...\\n', '______________________________________I bought the first version of this product because it came with two packs']\nSummaries: {'______________________________________I bought the first version of this product because it came with two packs'}\n\n\nI order this food to try as it was grain free and I liked the ingredients listed on the site with the reviews. I opened the bag and the smell was incredible. It almost made me hungry lol. The dog loves it and is doing well on it.<br />  I start doing more research on the food and was very impressed. The owners of this food make sure ethoxyquin, BHA and BHT (which are knowing to cause cancer) are NOT used at all in the food. They make sure that the slaughter and processing plants do not use them either. That is great and it show that they care as well.<br />  I have communicated with the Petcurean and have been very impressed with them as well. I am really happy with this food. It has very good ingredients. he company is great. I highly recommended this good and I have tired several different grain free dog foods.  Plus my dog loves it.<br />  Thank you amazon. i would have never found it without amazon. = Incrediblely Great food with great results.\n\nResult: I order this food to try as it was grain free and I liked the ingredients listed on the site with the reviews. I opened the bag and the smell was incredible. It almost made me hungry lol. The dog loves it and is doing well on it.<br />  I start doing more research on the food and was very impressed. The owners of this food make sure ethoxyquin, BHA and BHT (which are knowing to cause cancer) are NOT used at all in the food. They make sure that the slaughter and processing plants do not use them either. That is great and it show that they care as well.<br />  I have communicated with the Petcurean and have been very impressed with them as well. I am really happy with this food. It has very good ingredients. he company is great. I highly recommended this good and I have tired several different grain free dog foods.  Plus my dog loves it.<br />  Thank you amazon. i would have never found it without amazon. = Incrediblely Great food with great results.\n TL;DR  this is one of many great dog foods I have found that make me happy\nParts: ['I order this food to try as it was grain free and I liked the ingredients listed on the site with the reviews. I opened the bag and the smell was incredible. It almost made me hungry lol. The dog loves it and is doing well on it.<br />  I start doing more research on the food and was very impressed. The owners of this food make sure ethoxyquin, BHA and BHT (which are knowing to cause cancer) are NOT used at all in the food. They make sure that the slaughter and processing plants do not use them either. That is great and it show that they care as well.<br />  I have communicated with the Petcurean and have been very impressed with them as well. I am really happy with this food. It has very good ingredients. he company is great. I highly recommended this good and I have tired several different grain free dog foods.  Plus my dog loves it.<br />  Thank you amazon. i would have never found it without amazon. = Incrediblely Great food with great results.\\n', '\\xa0this is one of many great dog foods I have found that make me happy']\nSummaries: {'this is one of many great dog foods I have found that make me happy'}\n\n\nI was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor's has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I'd say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor's, for making a product that is so worth purchasing and using! Can't live, or at least cook, without my Minor's! = Cookin' in Arizona\n\nResult: I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor's has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I'd say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor's, for making a product that is so worth purchasing and using! Can't live, or at least cook, without my Minor's! = Cookin' in Arizona\n TL;DR!!!\nIf you like this recipe and want to make your own, then check\nParts: ['I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor\\'s has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I\\'d say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor\\'s, for making a product that is so worth purchasing and using! Can\\'t live, or at least cook, without my Minor\\'s! = Cookin\\' in Arizona\\n TL;DR!!!\\nIf you like this recipe and want to make your own, then check']\nSummaries: set()\nResult: I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor's has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I'd say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor's, for making a product that is so worth purchasing and using! Can't live, or at least cook, without my Minor's! = Cookin' in Arizona\n TL;DR!!!\n\nI am an avid chicken lover and my first purchase from Minor's\nParts: ['I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor\\'s has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I\\'d say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor\\'s, for making a product that is so worth purchasing and using! Can\\'t live, or at least cook, without my Minor\\'s! = Cookin\\' in Arizona\\n TL;DR!!!\\n\\nI am an avid chicken lover and my first purchase from Minor\\'s']\nSummaries: set()\nResult: I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor's has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I'd say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor's, for making a product that is so worth purchasing and using! Can't live, or at least cook, without my Minor's! = Cookin' in Arizona\n TL;DR!!! I was in my 30s when I first started using Minor's. It\nParts: ['I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor\\'s has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I\\'d say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor\\'s, for making a product that is so worth purchasing and using! Can\\'t live, or at least cook, without my Minor\\'s! = Cookin\\' in Arizona\\n TL;DR!!! I was in my 30s when I first started using Minor\\'s. It']\nSummaries: set()\nResult: I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor's has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I'd say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor's, for making a product that is so worth purchasing and using! Can't live, or at least cook, without my Minor's! = Cookin' in Arizona\n TL;DR _________________\n\n1. I have been using Minor's for a few days\nParts: ['I was given this product as a gift a couple of years ago. Up until that point I thought all \"bases\" were the same. NOT SO!! Minor\\'s has more flavor and tastes fresher than anything I have ever used. I cook with  all the bases but I\\'d say the flavor that gets the very most use (on a daily basis) is the chicken. I could not live without them all. Thank you Minor\\'s, for making a product that is so worth purchasing and using! Can\\'t live, or at least cook, without my Minor\\'s! = Cookin\\' in Arizona\\n', \"_________________\\n\\n1. I have been using Minor's for a few days\"]\nSummaries: {\"_________________\\n\\n1. I have been using Minor's for a few days\"}\n\n\nI absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\n\nResult: I absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\n TL;DR!!!\n\nNantucket Blend is one of the better Nantucket Blend\nParts: [\"I absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\\n TL;DR!!!\\n\\nNantucket Blend is one of the better Nantucket Blend\"]\nSummaries: set()\nResult: I absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\n TL;DR  I've been using the Vanilla Blend for years and this one is no exception\nParts: [\"I absolutely LOVE the Nantucket Blend! Its not too bold, but yet not too weak either! The flavor is great and with a splash of creamer I'm out the door! = YUMMMY\\n\", \"\\xa0I've been using the Vanilla Blend for years and this one is no exception\"]\nSummaries: {\"I've been using the Vanilla Blend for years and this one is no exception\"}\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EARLIER ROUGE 0","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split\n\n# Split the dataset into training and testing sets\ntrain_size = int(0.75 * len(dataset))  # Determine the size of the training set (75% of the dataset)\ntest_size = len(dataset) - train_size   # Determine the size of the testing set (remaining portion)\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])  # Split the dataset\n\n# Create data loaders for training and testing sets\n# Training DataLoader\ntrain_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n# Explanation:\n# - DataLoader: Creates an iterator that provides batches of data during training.\n# - train_dataset: The dataset used for training.\n# - batch_size: Number of samples in each batch.\n# - shuffle: Whether to shuffle the data at the beginning of each epoch (recommended for training).\n# - drop_last: Whether to drop the last incomplete batch if the dataset size is not divisible by the batch size.\n\n# Testing DataLoader\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n# Explanation:\n# - Similar to the training DataLoader but shuffling is set to False since shuffling is not needed during testing.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T04:43:18.065806Z","iopub.execute_input":"2024-04-23T04:43:18.066580Z","iopub.status.idle":"2024-04-23T04:43:18.135774Z","shell.execute_reply.started":"2024-04-23T04:43:18.066535Z","shell.execute_reply":"2024-04-23T04:43:18.134910Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Define your train function\ndef train(model, optimizer, train_dl, epochs):\n    for epoch in range(epochs):\n        model.train()  # Set model to training mode\n        for idx, batch in enumerate(train_dl):\n            optimizer.zero_grad()\n            batch = batch.to(device)\n            output = model(batch, labels=batch)\n            loss = output[0]\n            loss.backward()\n            optimizer.step()\n            if idx % 50 == 0:\n                print(f\"Epoch [{epoch+1}/{epochs}], Step [{idx+1}/{len(train_dl)}], Loss: {loss.item()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:01:57.590542Z","iopub.execute_input":"2024-04-23T05:01:57.590915Z","iopub.status.idle":"2024-04-23T05:01:57.597687Z","shell.execute_reply.started":"2024-04-23T05:01:57.590885Z","shell.execute_reply":"2024-04-23T05:01:57.596374Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Train the model on the training set\ntrain(model, optimizer, train_dataloader, epochs=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:32:18.848482Z","iopub.execute_input":"2024-04-22T13:32:18.848729Z","iopub.status.idle":"2024-04-22T15:15:46.943850Z","shell.execute_reply.started":"2024-04-22T13:32:18.848708Z","shell.execute_reply":"2024-04-22T15:15:46.942812Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Epoch [1/1], Step [1/13323], Loss: 1.8593367338180542\nEpoch [1/1], Step [51/13323], Loss: 1.9994953870773315\nEpoch [1/1], Step [101/13323], Loss: 1.8977000713348389\nEpoch [1/1], Step [151/13323], Loss: 2.0506272315979004\nEpoch [1/1], Step [201/13323], Loss: 1.5420185327529907\nEpoch [1/1], Step [251/13323], Loss: 1.4611223936080933\nEpoch [1/1], Step [301/13323], Loss: 2.0511529445648193\nEpoch [1/1], Step [351/13323], Loss: 1.8443139791488647\nEpoch [1/1], Step [401/13323], Loss: 2.04577898979187\nEpoch [1/1], Step [451/13323], Loss: 2.006317615509033\nEpoch [1/1], Step [501/13323], Loss: 1.8634902238845825\nEpoch [1/1], Step [551/13323], Loss: 2.206110715866089\nEpoch [1/1], Step [601/13323], Loss: 1.6728296279907227\nEpoch [1/1], Step [651/13323], Loss: 1.805537223815918\nEpoch [1/1], Step [701/13323], Loss: 1.817780613899231\nEpoch [1/1], Step [751/13323], Loss: 2.183117389678955\nEpoch [1/1], Step [801/13323], Loss: 2.004399538040161\nEpoch [1/1], Step [851/13323], Loss: 1.8522589206695557\nEpoch [1/1], Step [901/13323], Loss: 2.035400867462158\nEpoch [1/1], Step [951/13323], Loss: 2.096686840057373\nEpoch [1/1], Step [1001/13323], Loss: 2.0694565773010254\nEpoch [1/1], Step [1051/13323], Loss: 2.077425241470337\nEpoch [1/1], Step [1101/13323], Loss: 1.8684288263320923\nEpoch [1/1], Step [1151/13323], Loss: 1.8990898132324219\nEpoch [1/1], Step [1201/13323], Loss: 1.921075463294983\nEpoch [1/1], Step [1251/13323], Loss: 1.8216502666473389\nEpoch [1/1], Step [1301/13323], Loss: 2.0776424407958984\nEpoch [1/1], Step [1351/13323], Loss: 2.150500774383545\nEpoch [1/1], Step [1401/13323], Loss: 2.0110044479370117\nEpoch [1/1], Step [1451/13323], Loss: 1.669289469718933\nEpoch [1/1], Step [1501/13323], Loss: 1.914114236831665\nEpoch [1/1], Step [1551/13323], Loss: 1.8135563135147095\nEpoch [1/1], Step [1601/13323], Loss: 1.8757691383361816\nEpoch [1/1], Step [1651/13323], Loss: 1.7813657522201538\nEpoch [1/1], Step [1701/13323], Loss: 1.8469264507293701\nEpoch [1/1], Step [1751/13323], Loss: 1.8516680002212524\nEpoch [1/1], Step [1801/13323], Loss: 1.8303462266921997\nEpoch [1/1], Step [1851/13323], Loss: 1.9297868013381958\nEpoch [1/1], Step [1901/13323], Loss: 2.013068437576294\nEpoch [1/1], Step [1951/13323], Loss: 1.810950517654419\nEpoch [1/1], Step [2001/13323], Loss: 1.407564640045166\nEpoch [1/1], Step [2051/13323], Loss: 1.9109692573547363\nEpoch [1/1], Step [2101/13323], Loss: 2.1503963470458984\nEpoch [1/1], Step [2151/13323], Loss: 1.6724933385849\nEpoch [1/1], Step [2201/13323], Loss: 2.0952253341674805\nEpoch [1/1], Step [2251/13323], Loss: 1.7710704803466797\nEpoch [1/1], Step [2301/13323], Loss: 1.87917959690094\nEpoch [1/1], Step [2351/13323], Loss: 2.0899248123168945\nEpoch [1/1], Step [2401/13323], Loss: 1.8799912929534912\nEpoch [1/1], Step [2451/13323], Loss: 2.152127981185913\nEpoch [1/1], Step [2501/13323], Loss: 1.814243197441101\nEpoch [1/1], Step [2551/13323], Loss: 1.8825352191925049\nEpoch [1/1], Step [2601/13323], Loss: 1.594435453414917\nEpoch [1/1], Step [2651/13323], Loss: 1.9116588830947876\nEpoch [1/1], Step [2701/13323], Loss: 2.0606493949890137\nEpoch [1/1], Step [2751/13323], Loss: 1.8661918640136719\nEpoch [1/1], Step [2801/13323], Loss: 1.9912052154541016\nEpoch [1/1], Step [2851/13323], Loss: 1.7195786237716675\nEpoch [1/1], Step [2901/13323], Loss: 1.9012670516967773\nEpoch [1/1], Step [2951/13323], Loss: 1.9572492837905884\nEpoch [1/1], Step [3001/13323], Loss: 1.868570327758789\nEpoch [1/1], Step [3051/13323], Loss: 1.8950169086456299\nEpoch [1/1], Step [3101/13323], Loss: 1.8960697650909424\nEpoch [1/1], Step [3151/13323], Loss: 1.6383172273635864\nEpoch [1/1], Step [3201/13323], Loss: 1.7797762155532837\nEpoch [1/1], Step [3251/13323], Loss: 1.8346738815307617\nEpoch [1/1], Step [3301/13323], Loss: 1.9317412376403809\nEpoch [1/1], Step [3351/13323], Loss: 1.7183421850204468\nEpoch [1/1], Step [3401/13323], Loss: 1.9299323558807373\nEpoch [1/1], Step [3451/13323], Loss: 1.964643120765686\nEpoch [1/1], Step [3501/13323], Loss: 1.9855806827545166\nEpoch [1/1], Step [3551/13323], Loss: 1.9137684106826782\nEpoch [1/1], Step [3601/13323], Loss: 1.8044452667236328\nEpoch [1/1], Step [3651/13323], Loss: 1.9294006824493408\nEpoch [1/1], Step [3701/13323], Loss: 2.0807619094848633\nEpoch [1/1], Step [3751/13323], Loss: 1.625539779663086\nEpoch [1/1], Step [3801/13323], Loss: 1.9944671392440796\nEpoch [1/1], Step [3851/13323], Loss: 1.8847376108169556\nEpoch [1/1], Step [3901/13323], Loss: 1.8487818241119385\nEpoch [1/1], Step [3951/13323], Loss: 1.8154064416885376\nEpoch [1/1], Step [4001/13323], Loss: 2.1736629009246826\nEpoch [1/1], Step [4051/13323], Loss: 1.9455980062484741\nEpoch [1/1], Step [4101/13323], Loss: 2.0128092765808105\nEpoch [1/1], Step [4151/13323], Loss: 1.9527301788330078\nEpoch [1/1], Step [4201/13323], Loss: 1.9129643440246582\nEpoch [1/1], Step [4251/13323], Loss: 2.1127841472625732\nEpoch [1/1], Step [4301/13323], Loss: 1.857349157333374\nEpoch [1/1], Step [4351/13323], Loss: 2.178356647491455\nEpoch [1/1], Step [4401/13323], Loss: 1.9009180068969727\nEpoch [1/1], Step [4451/13323], Loss: 2.02463960647583\nEpoch [1/1], Step [4501/13323], Loss: 1.9291868209838867\nEpoch [1/1], Step [4551/13323], Loss: 2.142850399017334\nEpoch [1/1], Step [4601/13323], Loss: 1.8973115682601929\nEpoch [1/1], Step [4651/13323], Loss: 1.913365364074707\nEpoch [1/1], Step [4701/13323], Loss: 1.6300108432769775\nEpoch [1/1], Step [4751/13323], Loss: 1.8966221809387207\nEpoch [1/1], Step [4801/13323], Loss: 2.280146837234497\nEpoch [1/1], Step [4851/13323], Loss: 1.9418772459030151\nEpoch [1/1], Step [4901/13323], Loss: 1.7823336124420166\nEpoch [1/1], Step [4951/13323], Loss: 1.8024250268936157\nEpoch [1/1], Step [5001/13323], Loss: 2.1211421489715576\nEpoch [1/1], Step [5051/13323], Loss: 1.8038098812103271\nEpoch [1/1], Step [5101/13323], Loss: 2.0249433517456055\nEpoch [1/1], Step [5151/13323], Loss: 1.8319696187973022\nEpoch [1/1], Step [5201/13323], Loss: 1.8857462406158447\nEpoch [1/1], Step [5251/13323], Loss: 1.9605473279953003\nEpoch [1/1], Step [5301/13323], Loss: 2.2325241565704346\nEpoch [1/1], Step [5351/13323], Loss: 2.135392665863037\nEpoch [1/1], Step [5401/13323], Loss: 1.8125841617584229\nEpoch [1/1], Step [5451/13323], Loss: 1.9332795143127441\nEpoch [1/1], Step [5501/13323], Loss: 1.950486660003662\nEpoch [1/1], Step [5551/13323], Loss: 1.8388936519622803\nEpoch [1/1], Step [5601/13323], Loss: 2.12807035446167\nEpoch [1/1], Step [5651/13323], Loss: 1.6925292015075684\nEpoch [1/1], Step [5701/13323], Loss: 1.956146001815796\nEpoch [1/1], Step [5751/13323], Loss: 1.864489197731018\nEpoch [1/1], Step [5801/13323], Loss: 1.8688945770263672\nEpoch [1/1], Step [5851/13323], Loss: 1.8936350345611572\nEpoch [1/1], Step [5901/13323], Loss: 2.2162928581237793\nEpoch [1/1], Step [5951/13323], Loss: 1.838510274887085\nEpoch [1/1], Step [6001/13323], Loss: 1.779976725578308\nEpoch [1/1], Step [6051/13323], Loss: 1.80898916721344\nEpoch [1/1], Step [6101/13323], Loss: 1.8144537210464478\nEpoch [1/1], Step [6151/13323], Loss: 1.8902982473373413\nEpoch [1/1], Step [6201/13323], Loss: 2.067850351333618\nEpoch [1/1], Step [6251/13323], Loss: 1.9593560695648193\nEpoch [1/1], Step [6301/13323], Loss: 2.020855665206909\nEpoch [1/1], Step [6351/13323], Loss: 1.914980411529541\nEpoch [1/1], Step [6401/13323], Loss: 1.6727449893951416\nEpoch [1/1], Step [6451/13323], Loss: 2.0174825191497803\nEpoch [1/1], Step [6501/13323], Loss: 1.7671254873275757\nEpoch [1/1], Step [6551/13323], Loss: 2.213585615158081\nEpoch [1/1], Step [6601/13323], Loss: 2.0638558864593506\nEpoch [1/1], Step [6651/13323], Loss: 1.9222606420516968\nEpoch [1/1], Step [6701/13323], Loss: 1.8252533674240112\nEpoch [1/1], Step [6751/13323], Loss: 2.0222110748291016\nEpoch [1/1], Step [6801/13323], Loss: 2.0266642570495605\nEpoch [1/1], Step [6851/13323], Loss: 2.016759157180786\nEpoch [1/1], Step [6901/13323], Loss: 2.0608413219451904\nEpoch [1/1], Step [6951/13323], Loss: 2.0079097747802734\nEpoch [1/1], Step [7001/13323], Loss: 2.135938882827759\nEpoch [1/1], Step [7051/13323], Loss: 1.6093546152114868\nEpoch [1/1], Step [7101/13323], Loss: 1.6394188404083252\nEpoch [1/1], Step [7151/13323], Loss: 1.9668195247650146\nEpoch [1/1], Step [7201/13323], Loss: 1.8977442979812622\nEpoch [1/1], Step [7251/13323], Loss: 1.9204384088516235\nEpoch [1/1], Step [7301/13323], Loss: 1.8027960062026978\nEpoch [1/1], Step [7351/13323], Loss: 1.9839893579483032\nEpoch [1/1], Step [7401/13323], Loss: 2.0090181827545166\nEpoch [1/1], Step [7451/13323], Loss: 1.9405510425567627\nEpoch [1/1], Step [7501/13323], Loss: 1.806592583656311\nEpoch [1/1], Step [7551/13323], Loss: 2.1652944087982178\nEpoch [1/1], Step [7601/13323], Loss: 2.000552177429199\nEpoch [1/1], Step [7651/13323], Loss: 1.9964110851287842\nEpoch [1/1], Step [7701/13323], Loss: 1.9104042053222656\nEpoch [1/1], Step [7751/13323], Loss: 1.7111854553222656\nEpoch [1/1], Step [7801/13323], Loss: 1.6446475982666016\nEpoch [1/1], Step [7851/13323], Loss: 1.9736560583114624\nEpoch [1/1], Step [7901/13323], Loss: 1.8566796779632568\nEpoch [1/1], Step [7951/13323], Loss: 1.9211431741714478\nEpoch [1/1], Step [8001/13323], Loss: 2.0093679428100586\nEpoch [1/1], Step [8051/13323], Loss: 2.0747151374816895\nEpoch [1/1], Step [8101/13323], Loss: 2.04645037651062\nEpoch [1/1], Step [8151/13323], Loss: 1.6799840927124023\nEpoch [1/1], Step [8201/13323], Loss: 1.8120719194412231\nEpoch [1/1], Step [8251/13323], Loss: 1.954738974571228\nEpoch [1/1], Step [8301/13323], Loss: 1.9820940494537354\nEpoch [1/1], Step [8351/13323], Loss: 1.9676356315612793\nEpoch [1/1], Step [8401/13323], Loss: 2.058576822280884\nEpoch [1/1], Step [8451/13323], Loss: 2.2129595279693604\nEpoch [1/1], Step [8501/13323], Loss: 1.9552497863769531\nEpoch [1/1], Step [8551/13323], Loss: 1.8359630107879639\nEpoch [1/1], Step [8601/13323], Loss: 1.9980655908584595\nEpoch [1/1], Step [8651/13323], Loss: 1.960633635520935\nEpoch [1/1], Step [8701/13323], Loss: 1.973235845565796\nEpoch [1/1], Step [8751/13323], Loss: 1.8183228969573975\nEpoch [1/1], Step [8801/13323], Loss: 1.7930341958999634\nEpoch [1/1], Step [8851/13323], Loss: 1.8086961507797241\nEpoch [1/1], Step [8901/13323], Loss: 1.9198353290557861\nEpoch [1/1], Step [8951/13323], Loss: 1.634967565536499\nEpoch [1/1], Step [9001/13323], Loss: 1.6823698282241821\nEpoch [1/1], Step [9051/13323], Loss: 1.5595238208770752\nEpoch [1/1], Step [9101/13323], Loss: 1.905856728553772\nEpoch [1/1], Step [9151/13323], Loss: 1.7964011430740356\nEpoch [1/1], Step [9201/13323], Loss: 2.0394861698150635\nEpoch [1/1], Step [9251/13323], Loss: 1.6553316116333008\nEpoch [1/1], Step [9301/13323], Loss: 1.881771206855774\nEpoch [1/1], Step [9351/13323], Loss: 1.7127324342727661\nEpoch [1/1], Step [9401/13323], Loss: 2.0573887825012207\nEpoch [1/1], Step [9451/13323], Loss: 2.0987372398376465\nEpoch [1/1], Step [9501/13323], Loss: 1.5173234939575195\nEpoch [1/1], Step [9551/13323], Loss: 1.7963298559188843\nEpoch [1/1], Step [9601/13323], Loss: 1.910997986793518\nEpoch [1/1], Step [9651/13323], Loss: 2.147643566131592\nEpoch [1/1], Step [9701/13323], Loss: 1.7826851606369019\nEpoch [1/1], Step [9751/13323], Loss: 2.162510395050049\nEpoch [1/1], Step [9801/13323], Loss: 2.167438507080078\nEpoch [1/1], Step [9851/13323], Loss: 1.6650397777557373\nEpoch [1/1], Step [9901/13323], Loss: 1.9039068222045898\nEpoch [1/1], Step [9951/13323], Loss: 1.7916259765625\nEpoch [1/1], Step [10001/13323], Loss: 2.0217456817626953\nEpoch [1/1], Step [10051/13323], Loss: 1.981878638267517\nEpoch [1/1], Step [10101/13323], Loss: 1.8686474561691284\nEpoch [1/1], Step [10151/13323], Loss: 1.8873112201690674\nEpoch [1/1], Step [10201/13323], Loss: 1.7482918500900269\nEpoch [1/1], Step [10251/13323], Loss: 1.8134238719940186\nEpoch [1/1], Step [10301/13323], Loss: 1.646714687347412\nEpoch [1/1], Step [10351/13323], Loss: 1.7761223316192627\nEpoch [1/1], Step [10401/13323], Loss: 1.917398452758789\nEpoch [1/1], Step [10451/13323], Loss: 1.9740629196166992\nEpoch [1/1], Step [10501/13323], Loss: 1.8596736192703247\nEpoch [1/1], Step [10551/13323], Loss: 1.9144370555877686\nEpoch [1/1], Step [10601/13323], Loss: 1.6172658205032349\nEpoch [1/1], Step [10651/13323], Loss: 1.6614508628845215\nEpoch [1/1], Step [10701/13323], Loss: 1.906051516532898\nEpoch [1/1], Step [10751/13323], Loss: 2.0850167274475098\nEpoch [1/1], Step [10801/13323], Loss: 1.9570807218551636\nEpoch [1/1], Step [10851/13323], Loss: 1.7736315727233887\nEpoch [1/1], Step [10901/13323], Loss: 2.1388654708862305\nEpoch [1/1], Step [10951/13323], Loss: 2.089226484298706\nEpoch [1/1], Step [11001/13323], Loss: 1.9480562210083008\nEpoch [1/1], Step [11051/13323], Loss: 1.9375838041305542\nEpoch [1/1], Step [11101/13323], Loss: 2.136888027191162\nEpoch [1/1], Step [11151/13323], Loss: 1.8061046600341797\nEpoch [1/1], Step [11201/13323], Loss: 1.9908589124679565\nEpoch [1/1], Step [11251/13323], Loss: 1.9219461679458618\nEpoch [1/1], Step [11301/13323], Loss: 1.8890776634216309\nEpoch [1/1], Step [11351/13323], Loss: 1.9788035154342651\nEpoch [1/1], Step [11401/13323], Loss: 1.5357309579849243\nEpoch [1/1], Step [11451/13323], Loss: 1.8916996717453003\nEpoch [1/1], Step [11501/13323], Loss: 1.9336580038070679\nEpoch [1/1], Step [11551/13323], Loss: 1.730126142501831\nEpoch [1/1], Step [11601/13323], Loss: 2.1746695041656494\nEpoch [1/1], Step [11651/13323], Loss: 1.9233794212341309\nEpoch [1/1], Step [11701/13323], Loss: 2.0420734882354736\nEpoch [1/1], Step [11751/13323], Loss: 2.2696192264556885\nEpoch [1/1], Step [11801/13323], Loss: 1.8142954111099243\nEpoch [1/1], Step [11851/13323], Loss: 1.9056501388549805\nEpoch [1/1], Step [11901/13323], Loss: 2.222043752670288\nEpoch [1/1], Step [11951/13323], Loss: 1.994773507118225\nEpoch [1/1], Step [12001/13323], Loss: 2.131202459335327\nEpoch [1/1], Step [12051/13323], Loss: 2.012481212615967\nEpoch [1/1], Step [12101/13323], Loss: 1.7984973192214966\nEpoch [1/1], Step [12151/13323], Loss: 1.6288018226623535\nEpoch [1/1], Step [12201/13323], Loss: 2.115076780319214\nEpoch [1/1], Step [12251/13323], Loss: 1.8810100555419922\nEpoch [1/1], Step [12301/13323], Loss: 2.284257173538208\nEpoch [1/1], Step [12351/13323], Loss: 1.9468507766723633\nEpoch [1/1], Step [12401/13323], Loss: 2.0090150833129883\nEpoch [1/1], Step [12451/13323], Loss: 1.8493815660476685\nEpoch [1/1], Step [12501/13323], Loss: 1.8296180963516235\nEpoch [1/1], Step [12551/13323], Loss: 1.740234375\nEpoch [1/1], Step [12601/13323], Loss: 1.7949384450912476\nEpoch [1/1], Step [12651/13323], Loss: 2.080493450164795\nEpoch [1/1], Step [12701/13323], Loss: 1.6671286821365356\nEpoch [1/1], Step [12751/13323], Loss: 2.0497944355010986\nEpoch [1/1], Step [12801/13323], Loss: 1.820830225944519\nEpoch [1/1], Step [12851/13323], Loss: 1.7951972484588623\nEpoch [1/1], Step [12901/13323], Loss: 1.9189783334732056\nEpoch [1/1], Step [12951/13323], Loss: 1.8527307510375977\nEpoch [1/1], Step [13001/13323], Loss: 1.6524192094802856\nEpoch [1/1], Step [13051/13323], Loss: 1.9082450866699219\nEpoch [1/1], Step [13101/13323], Loss: 2.0996479988098145\nEpoch [1/1], Step [13151/13323], Loss: 1.6091285943984985\nEpoch [1/1], Step [13201/13323], Loss: 2.0307776927948\nEpoch [1/1], Step [13251/13323], Loss: 1.7898027896881104\nEpoch [1/1], Step [13301/13323], Loss: 1.7528245449066162\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = \"/kaggle/input/ir-model/model\"  # Specify the correct file path including the file extension\nmodel.load_state_dict(torch.load(model_path))\nmodel.eval()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:03:39.436855Z","iopub.execute_input":"2024-04-23T05:03:39.437876Z","iopub.status.idle":"2024-04-23T05:03:43.700159Z","shell.execute_reply.started":"2024-04-23T05:03:39.437830Z","shell.execute_reply":"2024-04-23T05:03:43.699084Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install rouge\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:04:45.310181Z","iopub.execute_input":"2024-04-23T05:04:45.311103Z","iopub.status.idle":"2024-04-23T05:04:45.315218Z","shell.execute_reply.started":"2024-04-23T05:04:45.311068Z","shell.execute_reply":"2024-04-23T05:04:45.314110Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install evaluate\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:04:57.134761Z","iopub.execute_input":"2024-04-23T05:04:57.135729Z","iopub.status.idle":"2024-04-23T05:05:27.083807Z","shell.execute_reply.started":"2024-04-23T05:04:57.135691Z","shell.execute_reply":"2024-04-23T05:05:27.082666Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nrouge = evaluate.load('rouge')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:10:24.737413Z","iopub.execute_input":"2024-04-23T05:10:24.738327Z","iopub.status.idle":"2024-04-23T05:10:26.993555Z","shell.execute_reply.started":"2024-04-23T05:10:24.738271Z","shell.execute_reply":"2024-04-23T05:10:26.992594Z"},"trusted":true},"execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d87330a2df041098ad2752f787d1f29"}},"metadata":{}}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:10:53.987794Z","iopub.execute_input":"2024-04-23T05:10:53.988573Z","iopub.status.idle":"2024-04-23T05:10:54.002103Z","shell.execute_reply.started":"2024-04-23T05:10:53.988528Z","shell.execute_reply":"2024-04-23T05:10:54.001010Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"rouge1 = []\nrouge2 = []\nrougeL = []\nrougeLsum = []\n\nmodel.eval()\nfor batch in test_dataloader:\n#     batch = {k: v.to(device) for k, v in batch.items()}\n    batch = batch.to(device)\n    with torch.no_grad():\n        outputs = model(batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    generated_output = tokenizer.decode(predictions[0], skip_special_tokens=True)\n    references = tokenizer.decode(batch[0], skip_special_tokens=True)\n    results = rouge.compute(predictions=[generated_output], references=[references])\n    rouge1.append(results['rouge1'])\n    rouge2.append(results['rouge2'])\n    rougeL.append(results['rougeL'])\n    rougeLsum.append(results['rougeLsum'])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T05:10:58.340644Z","iopub.execute_input":"2024-04-23T05:10:58.341456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'rouge1: {sum(rouge1)/len(rouge1)}\\nrouge2: {sum(rouge2)/len(rouge2)}\\nrougeL: {sum(rougeL)/len(rougeL)}\\nrougeLsum: {sum(rougeLsum)/len(rougeLsum)}')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:34:46.270212Z","iopub.execute_input":"2024-04-22T18:34:46.270962Z","iopub.status.idle":"2024-04-22T18:34:46.277626Z","shell.execute_reply.started":"2024-04-22T18:34:46.270930Z","shell.execute_reply":"2024-04-22T18:34:46.276629Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"rouge1: 0.4086952614760332\nrouge2: 0.0852688926207635\nrougeL: 0.2926001694066451\nrougeLsum: 0.297603059631863\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"inp = input(\"Enter Review text: \")\nmodel.eval()\ninp = tokenizer(inp, truncation=True, return_tensors=\"pt\").to(device)\noutput = model.generate(inp['input_ids'], max_length= 60)\ngenerated_output = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(f'Generate Summary: \\n{generated_output}')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T18:53:07.921811Z","iopub.execute_input":"2024-04-22T18:53:07.922723Z","iopub.status.idle":"2024-04-22T18:53:10.972987Z","shell.execute_reply.started":"2024-04-22T18:53:07.922687Z","shell.execute_reply":"2024-04-22T18:53:10.972101Z"},"trusted":true},"execution_count":159,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter Review text:  The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.\n"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Generate Summary: \nThe Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.\n\nThe Fender CD-60S Dreadn\n","output_type":"stream"}]},{"cell_type":"code","source":"from rouge import Rouge\nimport pandas as pd\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n\n# Define functions to calculate ROUGE scores\ndef calculate_rouge(hypothesis, reference):\n    rouge = Rouge()\n    scores = rouge.get_scores(hypothesis, reference)\n    return scores[0]\n\n# Define function to generate summary\ndef generate_summary(review_text):\n    inputs = tokenizer.encode(\"summarize: \" + review_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n    summary_ids = model.generate(inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary","metadata":{"execution":{"iopub.status.busy":"2024-04-22T16:35:14.151281Z","iopub.execute_input":"2024-04-22T16:35:14.152120Z","iopub.status.idle":"2024-04-22T16:35:14.159014Z","shell.execute_reply.started":"2024-04-22T16:35:14.152086Z","shell.execute_reply":"2024-04-22T16:35:14.158071Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the CSV file into a DataFrame\nreviews_df = pd.read_csv(reviews_path)\n\n# Iterate over the rows of the DataFrame\nfor index, row in reviews_df.iterrows():\n    review_text = row[\"Review Text\"]\n    reference_summary = row[\"Summary\"]\n    # Your code for processing each row goes here\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def topk(probs, n=9):\n    # The scores are initially softmaxed to convert to probabilities\n    probs = torch.softmax(probs, dim= -1)\n    \n    # PyTorch has its own topk method, which we use here\n    tokensProb, topIx = torch.topk(probs, k=n)\n    \n    # The new selection pool (9 choices) is normalized\n    tokensProb = tokensProb / torch.sum(tokensProb)\n\n    # Send to CPU for numpy handling\n    tokensProb = tokensProb.cpu().detach().numpy()\n\n    # Make a random choice from the pool based on the new prob distribution\n    choice = np.random.choice(n, 1, p = tokensProb)\n    tokenId = topIx[choice][0]\n\n    return int(tokenId)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_infer(model, tokenizer, review, max_length=15):\n    # Preprocess the init token (task designator)\n    review_encoded = tokenizer.encode(review)\n    result = review_encoded\n    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n\n    with torch.set_grad_enabled(False):\n        # Feed the init token to the model\n        output = model(initial_input)\n\n        # Flatten the logits at the final time step\n        logits = output.logits[0,-1]\n\n        # Make a top-k choice and append to the result\n        result.append(topk(logits))\n\n        # For max_length times:\n        for _ in range(max_length):\n            # Feed the current sequence to the model and make a choice\n            input = torch.tensor(result).unsqueeze(0).to(device)\n            output = model(input)\n            logits = output.logits[0,-1]\n            res_id = topk(logits)\n\n            # If the chosen token is EOS, return the result\n            if res_id == tokenizer.eos_token_id:\n                return tokenizer.decode(result)\n            else: # Append to the sequence \n                result.append(res_id)\n    # IF no EOS is generated, return after the max_len\n    return tokenizer.decode(result)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T16:22:01.953526Z","iopub.execute_input":"2024-04-22T16:22:01.953908Z","iopub.status.idle":"2024-04-22T16:22:01.962523Z","shell.execute_reply.started":"2024-04-22T16:22:01.953878Z","shell.execute_reply":"2024-04-22T16:22:01.961494Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"sample_reviews = [review.split(\" TL;DR \")[0] for review in random.sample(reviews, 5)]\nsample_reviews","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for review in sample_reviews:\n    summaries = set()\n    print(review)\n    while len(summaries) < 3:\n        summary = model_infer(model, tokenizer, review + \" TL;DR \").split(\" TL;DR \")[1].strip()\n        if summary not in summaries:\n            summaries.add(summary)\n    print(\"Summaries: \"+ str(summaries) +\"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}